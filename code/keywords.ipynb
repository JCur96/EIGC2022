{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for keyword extraction from Tweet text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below Jupyter Notebook contains a Python pipeline for extraxting keywords from Twitter text data using tf idf, and a comparison point of the KeyBERT algorithm. This notebook can be easily adapted for future use for basic keyword extraction tasks. \n",
    "\n",
    "Also bundled with this work is an R script for extracting keywords from Tweet text, using the RAKE algorithm. This too can be easily adapted for future work, with only minor modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword generation from scraped twitter text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# keywords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.corpus import stopwords \n",
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(text):\n",
    "    text = text.lower()\n",
    "    # remove tags\n",
    "    text = re.sub(\"&lt;/?.*?&gt;\", \"&lt;&gt;\", text)\n",
    "    # remove special characters and digits\n",
    "    text = re.sub(\"(\\\\d|\\\\W)+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key = lambda x: (x[1], x[0]), reverse = True)\n",
    "\n",
    "def extract_topN_from_vector(feature_names, sorted_items, topN = 10):\n",
    "    sorted_items = sorted_items[:topN]\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    for idx, score in sorted_items: \n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "    results = {}\n",
    "    for idx in range(len(feature_vals)): \n",
    "        results[feature_vals[idx]] = score_vals[idx]\n",
    "    return results\n",
    "\n",
    "def extract_all_from_vector(feature_names, sorted_items):\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    for idx, score in sorted_items: \n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "    results = {}\n",
    "    for idx in range(len(feature_vals)): \n",
    "        results[feature_vals[idx]] = score_vals[idx]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json of tweets / text \n",
    "df_idf = pd.read_json(\"../data/tweet_text.json\", lines = True) # change path as appropriate\n",
    "\n",
    "# process \n",
    "df_idf['text'] = df_idf['text'].apply(lambda x:pre_process(x))\n",
    "docs = df_idf['text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf idf calculation\n",
    "\n",
    "Note custom stopwords should be used as opposed to the default 'english' set used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_df=0.85, stop_words='english') \n",
    "word_count_vector=cv.fit_transform(docs)\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf = True, use_idf= True)\n",
    "tfidf_transformer.fit(word_count_vector)\n",
    "feature_names = cv.get_feature_names()\n",
    "tf_idf_vector = tfidf_transformer.transform(cv.transform(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_items = sort_coo(tf_idf_vector.tocoo())\n",
    "keywords = extract_topN_from_vector(feature_names, sorted_items, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keywords = extract_all_from_vector(feature_names, sorted_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out data for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object = json.dumps(all_keywords)\n",
    "\n",
    "with open(\"data/all_keywords.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "\n",
    "df_idf.to_csv(\"../data/text_for_R.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the first N (in this case 10) keywords generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===Top 10 Keywords===\")\n",
    "for k in keywords:\n",
    "    print(k, keywords[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with KeyBERT generated keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KeyBERT \n",
    "kw_model = KeyBERT()\n",
    "keywords = kw_model.extract_keywords(docs)\n",
    "\n",
    "print(kw_model.extract_keywords(docs, keyphrase_ngram_range=(2, 5), stop_words=None))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "365136c9fc59485ef868c2e113714fef173a743c00f798917136a873c2da2275"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
